import os
import re
import pdfplumber
from docx import Document as DocxDocument
from difflib import get_close_matches
from typing import Optional, List, Dict
from langchain.text_splitter import RecursiveCharacterTextSplitter
from smolagents import Tool
from gigasmol import GigaChatSmolModel


class RegulationSearchTool(Tool):
    name = "regulation_search"
    description = (
        "–ò—â–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ-–ø—Ä–∞–≤–æ–≤—ã—Ö –∞–∫—Ç–æ–≤ (–∏–∑ .pdf/.txt/.docx) –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ "
        "–∏, –∏—Å–ø–æ–ª—å–∑—É—è LLM, –æ–±—ä—è—Å–Ω—è–µ—Ç –∏—Ö –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º."
    )

    inputs = {
        "query": {
            "type": "string",
            "description": "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∏–ª–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º —Ç–µ–∫—Å—Ç–∞–º."
        }
    }

    output_type = "string"

    def __init__(self, model: GigaChatSmolModel, docs_path: str = "data/regulations"):
        super().__init__()
        self.model = model
        self.docs_path = docs_path
        self.text_chunks = self._load_chunks()

    def _load_chunks(self) -> List[Dict[str, str]]:
        print("[RegulationSearchTool] –ó–∞–≥—Ä—É–∂–∞—é –¥–æ–∫—É–º–µ–Ω—Ç—ã...")

        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        chunks = []

        for filename in os.listdir(self.docs_path):
            path = os.path.join(self.docs_path, filename)
            if not os.path.isfile(path):
                continue

            content = ""
            try:
                ext = filename.lower()
                if ext.endswith(".txt"):
                    with open(path, "r", encoding="utf-8") as f:
                        content = f.read()
                elif ext.endswith(".pdf"):
                    with pdfplumber.open(path) as pdf:
                        content = "\n".join(page.extract_text() or "" for page in pdf.pages)
                elif ext.endswith(".docx"):
                    doc = DocxDocument(path)
                    content = "\n".join([p.text for p in doc.paragraphs])
                else:
                    print(f"[!] –ü—Ä–æ–ø—É—â–µ–Ω –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–∞–π–ª: {filename}")
                    continue
            except Exception as e:
                print(f"[!] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {filename}: {e}")
                continue

            split = splitter.split_text(content)
            for chunk in split:
                clean = chunk.strip()
                if len(clean) >= 100:  # –æ—Ç—Å–µ–∫–∞–µ–º –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –∫—É—Å–∫–∏
                    chunks.append({"text": clean, "source": filename})

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(chunks)}")
        return chunks

    def forward(self, query: str) -> str:
        print(f"üîé –ü–æ–∏—Å–∫ –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–∫–µ: '{query}'")
        texts = [ch["text"] for ch in self.text_chunks]
        matches = get_close_matches(query, texts, n=5, cutoff=0.2)

        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if not matches:
            return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É."

        contexts = []
        for match in matches:
            match_clean = match.strip().replace("\n", " ")
            source = next((ch["source"] for ch in self.text_chunks if ch["text"] == match), "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç")
            contexts.append(f"[{source}]:\n{match_clean}")

        full_context = "\n\n".join(contexts)

        prompt = f"""
        –í—ã ‚Äî –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –≤ –æ–±–ª–∞—Å—Ç–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞.

        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–ª –≤–æ–ø—Ä–æ—Å:
        "{query}"

        –ù–∞–π–¥–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ-–ø—Ä–∞–≤–æ–≤—ã—Ö –∞–∫—Ç–æ–≤:

        {full_context}

        –ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤, –¥–∞–π—Ç–µ –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç. –û–±—ä—è—Å–Ω–∏—Ç–µ —Å—É—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∏ –ø—Ä–∞–≤ –∫–ª–∏–µ–Ω—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.
        """

        response = self.model(prompt)

        if isinstance(response, dict) and "content" in response:
            return response["content"]

        if isinstance(response, str):
            return response.strip()

        raise TypeError("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏: –æ–∂–∏–¥–∞–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ {'content': ...}")
